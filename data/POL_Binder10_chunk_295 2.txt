The Government remains committed to increasing transparency in this field and welcome thoughts from stakeholders on how this could be addressed in the future. Guidance for AI developers In November 2023, NCSC published their Secure AI Guidelines for AI developers which provided useful information to help inform the development of models and systems. Based on our evidence and stakeholder engagement, the Code will be the most suitable document to lead on from this because it sets out the specific actions that stakeholders across the AI supply chain need to implement to help protect users. We considered whether guidance targeted at a particular phase of the lifecycle may be useful, but based on the findings of DSITﾃ不 risk assessment, it was clear that there were risks in each phase that needed to be addressed. The Government welcomes feedback from AI developers if they believe further information on a particular area would be useful. Guidance for consumers While we advocate every user to take action to ensure their own digital safety and security, the Government is not progressing with this intervention because the burden for taking action to ensure a user is safe should not fall on a consumer in the first instance in the supply chain. The Code as well as the need for models and systems to be secure by design is essential if we want to ensure that consumers, businesses and the wider economy can continue to benefit from AI. Awareness campaign targeted at organisations and users to increase understanding of security in context of AI We recognise that there are many businesses in the UK who have not implemented AI within their infrastructure, and this may be because of a lack of understanding of what security requirements they should expect from AI developers as well as if they should have specific cyber security practices for AI models. However, our engagement and previous work has shown that the Code is a more effective lever to drive change because if we can ensure that the market is adopting the requirements then the burden on taking action will be significantly reduced on users. However, we would recommend that businesses take stock of DSITﾃ不 Cyber Governance Code, NCSCﾃ不 Business Toolkit as well as NCSCﾃ不 specific AI guidance for businesses to help inform their commercial decisions. Annex F: Bibliography of relevant publications mapped to principles by Mindgard [Amazon, 2023] Amazon, AWS Cloud Adoption Framework for Artificial Intelligence, Machine Learning, and Generative AI, Amazon White Paper, 2023. [ASD, 2023] Australian Signals Directorate, An introduction to Artificial Intelligence, 2023. [BSI1, 2023] Federal Office in Information Security, AI Security Concerns in a Nutshell, 2023. [Cisco, 2022]Cisco, The Cisco Responsible AI Framework, 2022. Online: https://www.cisco.com/c/dam/en_us/about/doing_business/trust-center/docs/cisco-responsible-artificial- intelligence-framework.pdf (https://www.cisco.com/c/dam/en_us/about/doing_business/trust-center/docs/cisco- responsible-artificial-intelligence-framework.pdf) [Deloitte, 2023] Deloitte, Safeguarding Generative Artificial Intelligence with Cybersecurity Measures, 2023. [ESLA, 2023] ESLA, European Lighthouse on Secure and Safe AI, 2023. [ENISA, 2023] ENISA, Multilayer Framework for Good Cybersecurity Practices for AI, ENISA, 2023. [Google, 2023] Google, Google Secure AI Approach Framework (SAIF), 2023. Online: https://services.google.com/fh/files/blogs/google_secure_ai_framework_approach.pdf (https://services.google.com/fh/files/blogs/google_secure_ai_framework_approach.pdf) [G7,