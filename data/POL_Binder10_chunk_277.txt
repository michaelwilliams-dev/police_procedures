secure coding techniques specific to AI development, with a focus on preventing and mitigating security vulnerabilities in AI algorithms, models, and associated software. 1.3.1 Developer training should also include content on how developers may leverage AI/LLMs to improve code security 1.4 Developers shall receive awareness training in the characteristics of machine learning and AI systems in general that make them especially complex (and hence particularly vulnerable to technical debt and security issues) Ð these often include convoluted data dependencies, multi-layered software architectures, and intricate configurations. Principle 2: Design your system for security as well as functionality and performance[footnote 24] Primarily applies to: System Operator [OWASP 2024, MITRE 2024, WEF 2024, ENISA 2023, NCSC 2023, BSI1 2023, Cisco 2022, Microsoft 2022, G7 2023, HHS 2021, OpenAI2 2024, ASD 2023, ICO 2020] 2.1 As part of deciding whether to create an AI system, a System Operator shall determine and document the business requirements and/or problem they are seeking to address. 2.1.1 Data controllers shall be part of internal discussions when determining the requirements and data needs of an AI system. NCSC Guidelines for Secure AI System Development - other areas to consider include: The complexity of the model they are using, specifically the chosen architecture and number of parameters. The modelÕs chosen architecture and number of parameters will, among other factors, affect how much training data it requires and how robust it is to changes in input data when in use. The appropriateness of the model for their use case and/or feasibility of adapting it to their specific need (for example by fine-tuning). The ability to align, interpret and explain their modelÕs outputs (for example for debugging, audit or regulatory compliance); there may be benefits to using simpler, more transparent models over large and complex ones which are more difficult to interpret. The characteristics of training dataset(s), including size, integrity, quality, sensitivity, age, relevance and diversity the value of using model hardening (such as adversarial training), regularisation and/or privacy enhancing techniques. The provenance and supply chains of components including the model or foundation model, training data and associated tools. See NCSC Machine Learning Principles (https://www.ncsc.gov.uk/collection/machine-learning) for more information. 2.2 To support the process of preparing data for an AI system, Developers shall document and audit trail the creation, operation, and life cycle management of models, datasets and prompts incorporated into the system. 2.1 2.3 If a Developer and/or System Operator decides to use an external Application Programming Interface (API), they shall apply appropriate controls to data that can be sent to services outside of their organisationÕs control, such as requiring users to log in and confirm before sending potentially sensitive information. 2.4 Data controllers shall ensure that the intended usage of the system is appropriate with the sensitivity of the data it was controlled on as well as the controls intended to ensure the safety of data. 2.5 Where the AI system will be interacting with other systems, (be they internal or external), Developers and System Operators shall ensure that the permissions